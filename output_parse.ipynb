{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../output/output_1.txt\") as f:\n",
    "    output = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3305"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = defaultdict(lambda : defaultdict(lambda : defaultdict(list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_type = None\n",
    "\n",
    "params = [\n",
    "    'Batch Size: ',\n",
    "    'The CPU usage is:  ',\n",
    "    ]\n",
    "\n",
    "parameter = None\n",
    "param_value = None\n",
    "batch_size = None\n",
    "for line in output:\n",
    "    line = line.strip()\n",
    "    if 'Attention Type' in line:\n",
    "        if 'flash_attention' in line:\n",
    "            attention_type = 'flash_attention'\n",
    "            continue\n",
    "    for param in params:\n",
    "        if param in line:\n",
    "            param_value = float(line.replace(param,\"\"))\n",
    "            if param == 'Batch Size: ':\n",
    "                batch_size = param_value\n",
    "            elif 'CPU usage' in param:\n",
    "                data['batch_size'][batch_size]['CPU'].append(param_value)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The CPU usage is:  '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Varying Batch Size\\n',\n",
       " 'Attention Type flash_attention\\n',\n",
       " 'Batch Size: 8\\n',\n",
       " 'Loading Vocab data/vocab.mini\\n',\n",
       " 'Vocab Size:  18649\\n',\n",
       " 'Loading Train Dataset data/corpus.mini.txt\\n',\n",
       " 'Loading Test Dataset None\\n',\n",
       " 'Creating Dataloader\\n',\n",
       " 'Building BERT model\\n',\n",
       " 'Creating BERT Trainer\\n',\n",
       " 'Total Parameters: 44336859\\n',\n",
       " 'Training Start\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'The CPU usage is:  31.3\\n',\n",
       " 'RAM memory % used: 14.0\\n',\n",
       " 'CPU Temperature: 16.8\\n',\n",
       " 'GPU Utilization\\n',\n",
       " '| ID | Name                    | Serial | UUID                                     || GPU temp. | GPU util. | Memory util. || Memory total | Memory used | Memory free || Display mode | Display active |\\n',\n",
       " '---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n',\n",
       " '|  0 | NVIDIA GeForce RTX 4090 | [N/A]  | GPU-d08024de-ce29-41df-bdda-ba1e44e9f74f ||       55C |       81% |          14% ||      24564MB |      3486MB |     20722MB || Disabled     | Disabled       |\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'The CPU usage is:  23.8\\n',\n",
       " 'RAM memory % used: 14.1\\n',\n",
       " 'CPU Temperature: 16.8\\n',\n",
       " 'GPU Utilization\\n',\n",
       " '| ID | Name                    | Serial | UUID                                     || GPU temp. | GPU util. | Memory util. || Memory total | Memory used | Memory free || Display mode | Display active |\\n',\n",
       " '---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n',\n",
       " '|  0 | NVIDIA GeForce RTX 4090 | [N/A]  | GPU-d08024de-ce29-41df-bdda-ba1e44e9f74f ||       56C |       74% |          14% ||      24564MB |      3486MB |     20722MB || Disabled     | Disabled       |\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'The CPU usage is:  25.2\\n',\n",
       " 'RAM memory % used: 14.4\\n',\n",
       " 'CPU Temperature: 16.8\\n',\n",
       " 'GPU Utilization\\n']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
